{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    }
   ],
   "source": [
    "#standard\n",
    "import jsonlines\n",
    "import collections\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True, formatter={'float_kind':'{:f}'.format})\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#unstandard\n",
    "import faiss\n",
    "#if GPU available\n",
    "res = faiss.StandardGpuResources()\n",
    "\n",
    "#for printing out first keys in dict\n",
    "from itertools import islice\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obj(name ):\n",
    "    with open('/fs/clip-quiz/dpeskov/modulation/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f) \n",
    "loaded_d = load_obj(\"prop_val_dd\")\n",
    "print(\"Example WikiData:\", take(1, loaded_d.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through WikiData and select items that have a given property\n",
    "#default is US and German citizenship\n",
    "def select_data(property1 = 'Q183', property2 = 'Q30'):\n",
    "    tots, tots2 = 0, 0 \n",
    "    germans, americans = {}, {}\n",
    "    for key in loaded_d.keys():\n",
    "        german_flag = False\n",
    "        american_flag = False\n",
    "        #all_dict[key] = list(set(all_dict[key]))\n",
    "        for vals in loaded_d[key]:   \n",
    "            if vals[0] =='P27' and vals[1] == property1:\n",
    "                tots+=1\n",
    "                german_flag = True\n",
    "            if vals[0] =='P27' and vals[1] == property2:\n",
    "                tots2+=1\n",
    "                american_flag = True\n",
    "\n",
    "        if german_flag:\n",
    "            germans[key] = loaded_d[key]\n",
    "        if american_flag:\n",
    "            americans[key] = loaded_d[key]\n",
    "\n",
    "    print(tots, tots2)\n",
    "    print(\"German:\", take(5, germans.items()))\n",
    "    print(\"Americans:\", take(5, americans.items()))\n",
    "    return (germans, americans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values(dictionary):\n",
    "    values = []\n",
    "    for item in dictionary.values():\n",
    "        vals_only = []\n",
    "        for (prop, val) in item:\n",
    "            \n",
    "            #if val[0] == 'Q':\n",
    "            vals_only.append(val)\n",
    "        values.append(vals_only)\n",
    "    return values\n",
    "\n",
    "def join(values):\n",
    "    joined = [' '.join(vals) for vals in values]\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "germans, americans = select_data()\n",
    "\n",
    "#extract values from germans and americans\n",
    "american_vals = extract_values(americans)\n",
    "german_vals = extract_values(germans)\n",
    "\n",
    "#extract values for all values for vocab training purposes\n",
    "all_vals = extract_values(loaded_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 22s, sys: 18.5 s, total: 4min 40s\n",
      "Wall time: 4min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#drop items that occur too rarely and too frequently\n",
    "vectorizer = CountVectorizer(min_df=1000, max_df=1000000)\n",
    "# #create vocab on ALL the data, so it's consistent across sub-matrices\n",
    "vectorizer.fit(join(all_vals))\n",
    "\n",
    "# #passing in vectorizer into a function causes kernel crash\n",
    "# #faiss requires dense matrices in float32\n",
    "american_matrix = vectorizer.transform(join(american_vals))\n",
    "american_matrix = american_matrix.toarray().astype('float32')\n",
    "\n",
    "german_matrix = vectorizer.transform(join(german_vals))\n",
    "german_matrix = german_matrix.toarray().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Dimensions: 1774\n",
      "True\n",
      "46081\n",
      "Nearest Neighbors  [[    0  1945 41530  1327  3427  1814]\n",
      " [    1 12895 13656    17 15009 22989]\n",
      " [    2 21530 22176 18741 40433 31854]\n",
      " [    3 19994 16331  3652 25033  3982]\n",
      " [    4  1686  4508 21507 21782 11931]]\n",
      "\n",
      "Distance Value  [[0.000000 12009611460608.000000 12009614606336.000000\n",
      "  12009614606336.000000 12009614606336.000000 12009614606336.000000]\n",
      " [0.000000 15.000000 15.000000 17.000000 17.000000 17.000000]\n",
      " [0.000000 2.000000 3.000000 3.000000 3.000000 3.000000]\n",
      " [0.000000 4.000000 4.000000 4.000000 4.000000 5.000000]\n",
      " [0.000000 0.000000 0.000000 0.000000 0.000000 0.000000]]\n",
      "Nearest Neighbors, Start:  [[17928 30095 11195 21820 13857 13234]\n",
      " [31195 11800 31790 20364 20556 35522]\n",
      " [    0  1945 41530  1327  3427  1814]\n",
      " [20240  9272 38762  1753 21619 28147]\n",
      " [29614 38196  4646 14657 40440 29550]]\n",
      "\n",
      "Nearest Neighbors, End:  [[ 9099 41357 14349 15903 27524 32256]\n",
      " [30161   902  5526  4882  3358  4116]\n",
      " [30161   902  5526  4882  3358  4116]\n",
      " [30161   902  5526  4882  3358  4116]\n",
      " [34184 13584 31262 32022 40834  6797]]\n",
      "CPU times: user 4.08 s, sys: 2.29 s, total: 6.37 s\n",
      "Wall time: 9.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def faiss_search(base_matrix, search_matrix):\n",
    "    assert len(base_matrix[0]) == len(search_matrix[0])\n",
    "        \n",
    "    print (\"Using Dimensions:\", len(base_matrix[0]))\n",
    "    d= len(base_matrix[0])\n",
    "\n",
    "    index_flat = faiss.IndexFlatL2(d)   # build the index\n",
    "    index = faiss.index_cpu_to_gpu(res, 0, index_flat)\n",
    "    print(index.is_trained)\n",
    "    index.add(base_matrix)                  # add vectors to the index\n",
    "    print(index.ntotal)\n",
    "\n",
    "    k = 6                             # we want to see 4 nearest neighbors\n",
    "    D, I = index.search(base_matrix[:5], k) # sanity check\n",
    "    print(\"Nearest Neighbors \", I)\n",
    "    print()\n",
    "    print(\"Distance Value \", D)\n",
    "    \n",
    "    D, I = index.search(search_matrix, k)     # actual search\n",
    "    print(\"Nearest Neighbors, Start: \", I[:5])                   # neighbors of the 5 first queries\n",
    "    print()\n",
    "    print(\"Nearest Neighbors, End: \", I[-5:])\n",
    "    return(D, I)\n",
    "\n",
    "D, I = faiss_search(german_matrix, american_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"german_nn\"\n",
    "\n",
    "inv_d_a, inv_d_g = {}, {}\n",
    "for index, key in enumerate(americans.keys()):\n",
    "    inv_d_a[index] = key\n",
    "    \n",
    "for index, key in enumerate(germans.keys()):\n",
    "    inv_d_g[index] = key\n",
    "\n",
    "nearest_n_dict = {}\n",
    "for index, nearest_n in enumerate(I):\n",
    "    nearest_n_dict[inv_d_a[index]] = [inv_d_g[item] for item in nearest_n]\n",
    "    \n",
    "def save_obj(obj, name ):\n",
    "    with open('/fs/clip-scratch/dpeskov/obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "save_obj(nearest_n_dict, EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marvin Mandel ['Moses Alexander', 'Christopher Memminger', 'Emil Anneke', 'Siegfried Guggenheim', 'Curt Teichert', 'John Peter Altgeld']\n",
      "Jay Munly ['Kurt Jahnke', 'Heiner Friedrich', 'Dirk Dirksen', 'Bernhard Tessmann', 'Philip William August, Count Palatine of Neuburg', 'Gottfried Michaelsen']\n",
      "Bob Bergen ['Robert Lindemann', 'Robert Fegg', 'Paulus Roetter', 'Kurt Jahnke', 'Gudo Hoegel', 'Robert Wiebking']\n",
      "Eli Perry ['Moses Alexander', 'Anthony Eickhoff', 'Curt Teichert', 'Gustavus Sessinghaus', 'Simon Bamberger', 'Kurt Jahnke']\n",
      "Julie Ditty ['Stephanie Gehrlein', 'Ria Sabay', 'Kirstin Freye', 'Antonia Matic', 'Svenja Weidemann', 'Justine Ozga']\n",
      "Mark S. Schweiker ['Nicholas J. Rusch', 'Emil Anneke', 'Curt Teichert', 'Moses Alexander', 'Heiner Friedrich', 'Shawn Bradley']\n",
      "Sam Langford ['Jürgen Brähmer', 'Rüdiger May', 'Dominik Britsch', 'Kurt Jahnke', 'Hamza Touba', 'Dimitri Sartison']\n",
      "Mike Budenholzer ['Hurl Beechum', 'Denis Wucherer', 'Lucca Staiger', 'Thorsten Leibenath', 'Cody Toppert', 'Dirk Bauermann']\n",
      "Bruce Lundvall ['Kurt Jahnke', 'Ramon Zenker', 'Heiner Friedrich', 'Bernhard Tessmann', 'Dirk Dirksen', 'Faderhead']\n",
      "Leland Cunningham ['Heinz Kaminski', 'Halton Arp', 'Ulf Mark Schneider', 'Kurt Jahnke', 'Sebastian F. Hönig', 'Heiner Friedrich']\n",
      "K. J. Parker ['Kurt Jahnke', 'Eugen Sandow', 'Heiner Friedrich', 'Ferdinand von Bismarck', 'Geoffrey Girard', 'Dirk Dirksen']\n",
      "Cheryl Patton ['Ingrid Finger', 'Iris Klein', 'Petra Hack', 'Shermine Shahrivar', 'Natascha Börger', 'Jana Beller']\n",
      "Deion Branch ['Kurt Jahnke', 'Kasim Edebali', 'Heiner Friedrich', 'Sebastian Vollmer', 'Mark Nzeocha', 'Dirk Dirksen']\n",
      "Austin da Luz ['Karl-Heinz Handschuh', 'Timo Staffeldt', 'Erich Goede', 'Florian Jungwirth', 'Dieter Nüssing', 'Hanno Behrens']\n",
      "Alex Shapiro ['Werner Josten', 'Ellen Auerbach', 'Adelheid Maria Eichner', 'Verena Wagner Lafferentz', 'Carola Bauckholt', 'Wilhelmina Koch']\n",
      "Garfield Smith ['Arvid Kramer', 'Tibor Pleiß', 'Dirk Mädrich', 'Guido Grünheid', 'Linda Fröhlich', 'Danilo Barthel']\n",
      "Lenny Moore ['Waldemar Hartmann', 'Kurt Jahnke', 'Rudi Cerne', 'Joko Winterscheidt', 'Heiner Friedrich', 'Jörg Wontorra']\n",
      "Ava Lowle Willing ['Ellen Auerbach', 'Uli Derickson', 'Käte Stresemann', 'Princess Alexandrine of Baden', 'Fanny Hesse', 'Metta von Oberg']\n",
      "Avraham Tehomi ['Kurt Jahnke', 'Heiner Friedrich', 'Dirk Dirksen', 'Bernhard Tessmann', 'Philip William August, Count Palatine of Neuburg', 'Gottfried Michaelsen']\n",
      "William T. Haines ['Emil Anneke', 'Nicholas J. Rusch', 'Curt Teichert', 'Moses Alexander', 'Siegfried Guggenheim', 'William IV, Duke of Jülich-Berg']\n",
      "Azure Ray ['Kurt Jahnke', 'Heiner Friedrich', 'Dirk Dirksen', 'Bernhard Tessmann', 'Werner Buchholz', 'Fritz Wiessner']\n",
      "Bill Butters ['Constantin Braun', 'Björn Krupp', 'Bruno Guttowski', 'Udo Kiessling', 'Florian Ondruschka', 'Hans Pienitz']\n",
      "Bill Pope ['Tobias A. Schliessler', 'Kurt Jahnke', 'Christoph Krauss', 'Heiner Friedrich', 'Philipp Sichler', 'Götz Dieter Plage']\n",
      "B. J. Armstrong ['Per Günther', 'Sebastian Schmitt', 'Karsten Tadda', 'Cody Toppert', 'Misan Haldin', 'Isaiah Hartenstein']\n",
      "C. K. Garrison ['Kurt Jahnke', 'Tommi Parzinger', 'Ludwig Halberstädter', 'Heiner Friedrich', 'Julius Stern (producer)', 'Dirk Dirksen']\n",
      "Cedric Lewis ['Isaiah Philmore', 'Guido Grünheid', 'Danilo Barthel', 'Cody Toppert', 'Maximilian Kleber', 'Isaiah Hartenstein']\n",
      "Linwood Clark ['Gustavus A. Finkelnburg', 'Emil Anneke', 'Gustavus Sessinghaus', 'Nicholas J. Rusch', 'Klaus Winter', 'Werner Neumann (judge)']\n",
      "Bashful Brother Oswald ['Dirk Schlächter', 'Jens Ludwig', 'Günter Schulz', 'Caspar Brötzmann', 'Ralf Illenberger', 'Jürgen Rost']\n",
      "Ben Allison ['Rudi Mahall', 'Buschi Niebergall', 'Theo Jörgensmann', 'Wawau Adler', 'Ugonna Okegwo', 'Heiner Friedrich']\n",
      "Ben Street ['Rudi Mahall', 'Buschi Niebergall', 'Theo Jörgensmann', 'Wawau Adler', 'Ugonna Okegwo', 'Heiner Friedrich']\n"
     ]
    }
   ],
   "source": [
    "examples = ind_mat[1000:1030]\n",
    "for ex in examples:\n",
    "    print (inv_d_a[ex], nearest_n_dict[inv_d_a[ex]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Demond Greene',\n",
       " 'Sergio Kerusch',\n",
       " 'Steffen Hamann',\n",
       " 'Pascal Roller',\n",
       " 'Hurl Beechum',\n",
       " 'Sebastian Schmitt']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_n_dict['Kobe Bryant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79294\n"
     ]
    }
   ],
   "source": [
    "tots = 0\n",
    "ind_mat = []\n",
    "for index, i in enumerate(D):\n",
    "    if i[0] == 3:\n",
    "        tots+=1\n",
    "        ind_mat.append(index)\n",
    "print(tots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Oscar Holderer', 'Gerhard Neumann', 'Gerhard Fischer (inventor)', 'August Schrader', 'Felix Salm-Salm', 'Fritz Mueller']\n"
     ]
    }
   ],
   "source": [
    "for key, vals in nearest_n_dict.items():\n",
    "    print(vals)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('George Washington',\n",
       "  ['Ivan Fioletov',\n",
       "   'George Balanchine',\n",
       "   'Ruslan Gelayev',\n",
       "   'Bogdan Belsky',\n",
       "   'Mikhail Batin',\n",
       "   'Sergey Semyonovich Khabalov']),\n",
       " ('Larry Sanger',\n",
       "  ['Prince Rostislav Romanov (born 1985)',\n",
       "   'Vic Wild',\n",
       "   'Leo II of Galicia',\n",
       "   'Alexey Dyumin',\n",
       "   'Maxim Lykov',\n",
       "   'Aleksey Galkin']),\n",
       " (None,\n",
       "  [None,\n",
       "   'Vladimir Posner',\n",
       "   'Anna Politkovskaya',\n",
       "   'Sophie Shevardnadze',\n",
       "   'Yulia Latynina',\n",
       "   'Vladimir Putin']),\n",
       " ('Jenna Jameson',\n",
       "  ['Irina Pantaeva',\n",
       "   'Tatyana Kosmacheva',\n",
       "   'Marina Aleksandrova',\n",
       "   'Edelweiss (actress)',\n",
       "   'Ludmilla Radchenko',\n",
       "   'Anna Ukolova']),\n",
       " ('Bill Maher',\n",
       "  ['Oleg Stefan',\n",
       "   'Ivan Dobronravov',\n",
       "   'Andrei Dementiev (actor)',\n",
       "   'Maxim Munzuk',\n",
       "   'Grigoriy Dobrygin',\n",
       "   'Vitali Konyayev']),\n",
       " ('Joseph Brodsky',\n",
       "  ['Andrey Krasko',\n",
       "   'Roman Trakhtenberg',\n",
       "   'Lev Gumilyov',\n",
       "   'Elena Shvarts',\n",
       "   'Yevgeny Rein',\n",
       "   'Anatoly Naiman']),\n",
       " ('Gary Gygax',\n",
       "  ['Ille Takhti',\n",
       "   'Prince Rostislav Romanov (born 1985)',\n",
       "   'Mikhail Samarsky',\n",
       "   'Anatoly Serep',\n",
       "   'Shimun Vrochek',\n",
       "   'Aleksey Galkin']),\n",
       " ('Cyndi Lauper',\n",
       "  ['Oleg Stefan',\n",
       "   'Lyudmila Zajtseva',\n",
       "   'Elena Kamburova',\n",
       "   'Helena Holl',\n",
       "   'Yelena Terleyeva',\n",
       "   'Tatyana Voronina']),\n",
       " ('Jason Richardson',\n",
       "  ['Aleksei Zozulin',\n",
       "   'Egor Vyaltsev',\n",
       "   'Evgeny Baburin',\n",
       "   'Travis Hansen',\n",
       "   'Igor Kudelin',\n",
       "   'Evgeny Kolesnikov']),\n",
       " ('Erik Kynard',\n",
       "  ['Ivan Ukhov',\n",
       "   'Aleksey Dremin',\n",
       "   'Yegor Nikolayev',\n",
       "   'Sergey Bakulin',\n",
       "   'Andrey Krivov',\n",
       "   'Vyacheslav Sakayev'])]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D[:5]\n",
    "take(5, nearest_n_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#crashes for some reason\n",
    "\n",
    "def dict_transform(dictionary, vocab):\n",
    "    sparse_matrix = vocab.transform(join(dictionary))\n",
    "    dense = sparse_matrix.toarray().astype('float32')\n",
    "    return dense\n",
    "\n",
    "american_matrix = dict_transform(american_vals, vectorizer)\n",
    "german_matrix = dict_transform(german_vals, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_d = {}\n",
    "for index, key in enumerate(loaded_d.keys()):\n",
    "    inv_d[index] = key\n",
    "\n",
    "nearest_n_dict = {}\n",
    "for index, nearest_n in enumerate(I):\n",
    "    nearest_n_dict[inv_d[index]] = [inv_d[item] for item in nearest_n]\n",
    "    #print (inv_d[index])\n",
    "    #print (\"TOP 5: \", [inv_d[item] for item in nearest_n], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= load_obj(\"all_data_nn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Germany',\n",
       " 'Italy',\n",
       " 'Australia',\n",
       " 'International E-road network',\n",
       " 'European Union',\n",
       " 'Brazil']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Germany']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "similarities = cosine_similarity(sparse_matrix, dense_output = False)\n",
    "#print('pairwise dense output:\\n {}\\n'.format(similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (-similarities[99]).argsort()[:10]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000\n",
      "200000000\n",
      "300000000\n",
      "400000000\n",
      "500000000\n",
      "finished\n",
      "CPU times: user 50min 4s, sys: 2min 57s, total: 53min 1s\n",
      "Wall time: 53min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final = {}\n",
    "count = 0\n",
    "\n",
    "with jsonlines.open('/fs/clip-quiz/dpeskov/modulation/10-26-20-wikidata.jsonl') as reader:\n",
    "        all_dict = {}\n",
    "        count = 0\n",
    "        \n",
    "        for obj in reader:\n",
    "            if obj['title'] not in all_dict.keys():\n",
    "                #print(obj)\n",
    "                all_dict[obj['title']] = list()\n",
    "                #c = collections.Counter()\n",
    "                #c = collections.defaultdict(int)\n",
    "                #all_dict[obj['title']] = c\n",
    "            all_dict[obj['title']].append([obj['property'],obj['value']])\n",
    "            #all_dict[obj['title']][obj['property']]+=1\n",
    "            count+=1\n",
    "            if count % 100000000 == 0:\n",
    "                print (count)\n",
    "           # else:\n",
    "             #   break\n",
    "\n",
    "            \n",
    "print(\"finished\")            \n",
    "#\n",
    "# tots, tots2 = 0, 0                \n",
    "# for key in all_dict.keys():\n",
    "#     #all_dict[key] = list(set(all_dict[key]))\n",
    "#     for vals in all_dict[key]:\n",
    "#         #print(vals[0])\n",
    "#         if vals[0] =='P27' and vals[1] == 'Q183':\n",
    "#             #print (key)\n",
    "#             tots+=1\n",
    "#         if vals[0] =='P27' and vals[1] == 'Q30':\n",
    "#             tots2+=1\n",
    "#             break\n",
    "# print(tots, tots2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obj(name ):\n",
    "    with open('/fs/clip-scratch/dpeskov/obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "loaded_d = load_obj(\"prop_val_dd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loaded_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for item in loaded_d.values():\n",
    "    vals_only = []\n",
    "    for (prop, val) in item:\n",
    "        if val[0] == 'Q':\n",
    "            vals_only.append(val)\n",
    "    values.append(vals_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(values)\n",
    "faiss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "flat_list = [item for sublist in values for item in sublist]\n",
    "print(len(flat_list))\n",
    "vocab = vectorizer.fit(flat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = [' '.join(vals) for vals in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vectorizer = CountVectorizer()\n",
    "sparse_matrix = vectorizer.fit_transform(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "transformed = vocab.transform(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "docs = values[:5]\n",
    "indptr = [0]\n",
    "indices = []\n",
    "data = []\n",
    "vocabulary = {}\n",
    "for d in docs:\n",
    "    for term in d:\n",
    "        index = vocabulary.setdefault(term, len(vocabulary))\n",
    "        indices.append(index)\n",
    "        data.append(1)\n",
    "    indptr.append(len(indices))\n",
    "\n",
    "sparse_matrix = csr_matrix((data, indices, indptr), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import sklearn.preprocessing as pp\n",
    "\n",
    "def cosine_similarities(mat):\n",
    "    col_normed_mat = pp.normalize(mat.tocsc(), axis=0)\n",
    "    return col_normed_mat.T * col_normed_mat\n",
    "similarities = cosine_similarities(sparse_matrix)\n",
    "print('pairwise dense output:\\n {}\\n'.format(similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tots, tots2 = 0, 0                \n",
    "ger, eng = {}, {}\n",
    "for key in loaded_d.keys():\n",
    "    #all_dict[key] = list(set(all_dict[key]))\n",
    "    for vals in loaded_d[key]:\n",
    "        #print(vals[0])\n",
    "        if vals[0] =='P27' and vals[1] == 'Q183':\n",
    "            #print (key)\n",
    "            tots+=1\n",
    "            ger\n",
    "        if vals[0] =='P27' and vals[1] == 'Q30':\n",
    "            tots2+=1\n",
    "            break\n",
    "print(tots, tots2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('dd_prop_val.jsonl', 'w') as writer:\n",
    "    writer.write_all(all_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "with jsonlines.open('/fs/clip-scratch/dpeskov/obj/prop_val_dd.jsonl') as reader:\n",
    "        all_dict = {}\n",
    "        for obj in reader:\n",
    "            print(obj)\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict['Scotland']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('dd_prop_val.jsonl') as reader:\n",
    "        for obj in reader:\n",
    "            print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict['Richard Wagner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('/fs/clip-quiz/dpeskov/modulation/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "save_obj(all_dict, \"prop_val_dd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('/fs/clip-quiz/dpeskov/modulation/GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "len([v for v in model.vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_vocab = [v.lower() for v in model.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_dict = dict.fromkeys(word2vec_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vec = load_obj(\"binary_property_vector_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy\n",
    "#ary = scipy.spatial.distance.cdist(loaded_vec[key], loaded_vec.values(), metric='euclidean')\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "new_dict = {}\n",
    "\n",
    "count = 0\n",
    "for key in loaded_vec.keys():\n",
    "    count +=1\n",
    "    if count > 2:\n",
    "        break\n",
    "    for key2 in loaded_vec.keys():\n",
    "        if key != key2:\n",
    "            a = loaded_vec[key]\n",
    "            b = loaded_vec[key]\n",
    "            cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "            #ary = scipy.spatial.distance.cdist(loaded_vec[key], loaded_vec.values(), metric='euclidean')\n",
    "            #print(cosine_similarity(loaded_vec[key], loaded_vec[key2]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scipy.sparse.csr_matrix.todense(loaded_vec[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vec[key].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(loaded_vec.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import numpy as np\n",
    "A_sparse = sparse.csr_matrix(loaded_vec.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count, not_count = 0, 0\n",
    "for key in loaded_d.keys():\n",
    "    #print(key.split()[0])\n",
    "    if key:\n",
    "        if key.split()[-1] in model.vocab:\n",
    "            #print(\"FOUND\", key)\n",
    "            count +=1\n",
    "        else:\n",
    "            not_count +=1\n",
    "            #print(\"NOT FOUND\", key)\n",
    "            #\n",
    "        #if count >20:\n",
    "        #    break\n",
    "print(count, not_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "loaded_d = load_obj(\"propertydd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_d['Adolf Hitler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in loaded_d.keys():\n",
    "    loaded_d[key] = list(loaded_d[key].keys())\n",
    "\n",
    "values = []\n",
    "for item in loaded_d.values():\n",
    "    values.extend(item)\n",
    "values = list(set(values))    \n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(values)\n",
    "\n",
    "for key,val in loaded_d.items():\n",
    "    print(key,val)\n",
    "    \n",
    "    item = vectorizer.transform(val)\n",
    "    print((item).todense())\n",
    "    print((item).todense().shape)\n",
    "    loaded_d[key] = item\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(loaded_d['Scotland'])[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "new_dict = {}\n",
    "for key in loaded_d.keys():\n",
    "    if count < 500000:\n",
    "        new_dict[key] = list(loaded_d[key].keys())\n",
    "        count+=1\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "values = []\n",
    "for item in new_dict.values():\n",
    "    values.extend(item)\n",
    "values = list(set(values))    \n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(values)\n",
    "#vector = vectorizer.transform(text)\n",
    "for key,val in new_dict.items():\n",
    "    item = vectorizer.transform(val)\n",
    "    new_dict[key] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savez_compressed(\"binary_property_vector.npy\", loaded_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(new_dict, \"binary_property_vector_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(all_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
